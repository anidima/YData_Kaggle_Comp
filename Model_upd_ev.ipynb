{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices - Regression Predictions YData 2024    \n",
    "\n",
    "**Team: Random Forest Rangers** ([Dmitry Gufranov](https://www.linkedin.com/in/gufranov/), [Evgenia Amineva](https://www.linkedin.com/in/janeami/), [Valeriya Vazhnova](https://www.linkedin.com/in/gufranov/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime\n",
    "\n",
    "# vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# ml\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoCV, Ridge, RidgeCV, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler,  RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the train data\n",
    "df = pd.read_csv('train.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lists were created in Feat_eng_expl file\n",
    "\n",
    "cat_cols_oe = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "cat_cols_oh = ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', \\\n",
    "               'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \\\n",
    "                'Heating', 'CentralAir', 'Electrical', 'Functional', 'GarageType', 'GarageFinish', 'PavedDrive', 'Fence', 'SaleType', \\\n",
    "                'SaleCondition', 'MSSubClass', 'OverallCond', 'KitchenAbvGr', 'MoSold', 'YrSold']\n",
    "\n",
    "cat_cols_tdrop = ['Street', 'Utilities', 'LandSlope', 'Condition2', 'RoofMatl', 'PoolQC', 'MiscFeature', 'MiscVal']\n",
    "\n",
    "num_cols_norm = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', \\\n",
    "                 '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']\n",
    "\n",
    "num_cols_asis = ['OverallQual', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\n",
    "\n",
    "num_cols_tdrop = ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']\n",
    "\n",
    "num_cols_flag = ['BsmtFinSF2', 'LowQualFinSF', '3SsnPorch', 'PoolArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def fill_miss(df):\n",
    "\n",
    "    df_upd = df.copy()\n",
    "\n",
    "    # fill columns wheare missing values have a meaning NA\n",
    "    feat_wn = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu',\n",
    "       'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtFinType2', 'BsmtExposure',\n",
    "       'BsmtFinType1', 'BsmtCond', 'BsmtQual']\n",
    "    \n",
    "    for c in df_upd.columns:\n",
    "        if c in feat_wn:\n",
    "            df_upd[c].fillna('NA', inplace=True)\n",
    "\n",
    "    # fill columns wheare missing values have a meaning 0 (they appear in test data set)\n",
    "    feat_w0 = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "       'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'MasVnrArea']   \n",
    "\n",
    "    for c in df_upd.columns:\n",
    "            if c in feat_w0:\n",
    "                df_upd[c].fillna(0, inplace=True)\n",
    "\n",
    "    if 'LotFrontage' in df_upd.columns:\n",
    "        df_upd['LotFrontage'] = df_upd.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))\n",
    "     \n",
    "\n",
    "    # fill with mean missing num features\n",
    "    num_si = SimpleImputer(strategy='mean')\n",
    "    num_col= df_upd.dtypes[df_upd.dtypes != 'object']\n",
    "    df_upd[num_col.index] = num_si.fit_transform(df_upd[num_col.index])\n",
    "\n",
    "    # fill with most frequent categorical features\n",
    "    cat_si = SimpleImputer(strategy='most_frequent')\n",
    "    cat_col= df_upd.dtypes[df_upd.dtypes == 'object']\n",
    "    df_upd[cat_col.index] = cat_si.fit_transform(df_upd[cat_col.index])\n",
    "\n",
    "\n",
    "    return df_upd\n",
    "\n",
    "def feat_eng(df, num_cols_tdrop, num_cols_norm, num_cols_flag):\n",
    "    df_upd = df.copy()\n",
    "\n",
    "\n",
    "    # create new feature for bathrooms\n",
    "    # corr coef\n",
    "    #     0.22512486719612368\n",
    "    # -0.012188876310787316\n",
    "    # 0.6359570562496957\n",
    "    # 0.34300754918568294\n",
    "\n",
    "    df_upd['Bath'] = 0.225 * df['BsmtFullBath'] + (-0.0121) * df['BsmtHalfBath'] + 0.636 * df['FullBath'] + 0.343 * df['HalfBath']\n",
    "\n",
    "    # drop columns\n",
    "    df_upd = df_upd.drop(num_cols_tdrop, axis=1)\n",
    "\n",
    "    # # normalizing\n",
    "    # power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    # df_upd[num_cols_norm] = power.fit_transform(df_upd[num_cols_norm])\n",
    "\n",
    "    for c in num_cols_flag:\n",
    "        if c in df_upd.columns:\n",
    "            df_upd[c] = df_upd[c].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "\n",
    "    return df_upd\n",
    "\n",
    "def transf_cat(df, cat_cols_oh, cat_cols_oe, cat_cols_tdrop):\n",
    "    df_upd = df.copy()\n",
    "\n",
    "    # merge values in LotConfig\n",
    "    if 'LotConfig' in  df_upd.columns:\n",
    "        df_upd.loc[df_upd['LotConfig']=='FR3', 'LotConfig'] = 'FR2'\n",
    "\n",
    "\n",
    "    #\n",
    "    if 'LandSlope' in  df_upd.columns:\n",
    "        df_upd.loc[df_upd['LandSlope']=='Sev', 'LandSlope'] = 'Mod'\n",
    "        df_upd['GtlSlope'] = df_upd['LandSlope'].apply(lambda x: 1 if x=='Gtl' else 0)\n",
    "        df_upd[['LandSlope', 'GtlSlope']][:5]\n",
    "\n",
    "    # merge values in Conditional1\n",
    "    for cc in [['RRNn', 'RRAn'], ['RRNe', 'RRAe'], ['PosN', 'PosA']]:\n",
    "        df_upd.loc[df_upd['Condition1']==cc[0], 'Condition1'] = cc[1]\n",
    "\n",
    "\n",
    "    # transform \n",
    "    oec = OrdinalEncoder(categories = [['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']]) \n",
    "    # for cc in ['FireplaceQu', 'KitchenQual', 'HeatingQC', 'PoolQC', 'BsmtQual', 'ExterQual', 'ExterCond']:\n",
    "    for cc in cat_cols_oe:\n",
    "        if cc in df_upd.columns:\n",
    "            df_upd[cc] = oec.fit_transform(df_upd[[cc]])\n",
    "\n",
    "    \n",
    "    class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, *args, pandas_params={}, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self._pandas_params = pandas_params\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "        def transform(self, X, y=None):\n",
    "            return pd.get_dummies(X, dtype = 'int', **self._pandas_params)\n",
    "    \n",
    "    df_upd = GetDummiesTransformer(pandas_params={'columns':cat_cols_oh}).transform(df_upd)\n",
    "\n",
    "    df_upd = df_upd.drop(cat_cols_tdrop, axis=1)\n",
    "\n",
    "    return df_upd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models\n",
    "\n",
    "Since linear models sensitive to correlation, we will remove features which have high correlation with each other. They are fixed in <b>col_tdrop_linm</b> \n",
    "\n",
    "What was tested:\n",
    "<h5>1. - wo #1stFlrSF', '2ndFlrSF', <br>\n",
    "- with MinMaxScaler()</h5><br>\n",
    "\n",
    "1.1. <b>Lasso</b>(alpha=0.0, random_state=44) | grid search was {'alpha': np.arange(0.00, 1.0, 0.005), 'max_iter': [1000, 1200], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.124<br>\n",
    "R2: 0.900 <br>\n",
    "it doesn't converege<br>\n",
    "kaggle: 0.15107<br>\n",
    "\n",
    "1.2. <b>LassoCV</b><br>\n",
    "return parametrs\n",
    "{'alphas': None, 'copy_X': True, 'cv': None, 'eps': 0.001, 'fit_intercept': True, 'max_iter': 1000, 'n_alphas': 100, 'n_jobs': None, 'positive': False, 'precompute': 'auto', 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'verbose': False}<br>\n",
    "RMSE: 0.134<br>\n",
    "R2: 0.884 <br>\n",
    "kaggle - \n",
    "\n",
    "1.3. <b>Lasso</b>(alpha=0.001, max_iter=100, random_state=44) | grid search was {'alpha': np.arange(0.001, 1.0, 0.002), 'max_iter': [100, 300, 1000, None], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.112<br>\n",
    "R2: 0.918 <br>\n",
    "kaggle: <b>0.14718</b>\n",
    "\n",
    "1.4. <b>RidgeCV</b><br>\n",
    "Testing performance\n",
    "{'alpha_per_target': False, 'alphas': (0.1, 1.0, 10.0), 'cv': None, 'fit_intercept': True, 'gcv_mode': None, 'scoring': None, 'store_cv_values': False}<br>\n",
    "RMSE: 0.109<br>\n",
    "R2: 0.923 <br>\n",
    "kaggle: 0.14996<br>\n",
    "\n",
    "<h5>2. - with Power Transformer ()</h5><br>\n",
    "2.1. <b>Lasso</b> (alpha=0.001, max_iter=100, random_state=44) | GS was {'alpha': np.arange(0.001, 1.0, 0.002), 'max_iter': [100, 300, 1000, None], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.109<br>\n",
    "R2: 0.923 <br>\n",
    "kaggle: 0.14174\n",
    "\n",
    "2.2. <b>Ridge</b>(alpha=2.95, max_iter=1000, random_state=44) | GS was {'alpha': np.arange(0.00, 3.0, 0.05), 'max_iter': [1000, None], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.109<br>\n",
    "R2: 0.923 <br>\n",
    "kaggle: 0.14072\n",
    "\n",
    "\n",
    "\n",
    "<h5>3. <b>all features with Power Transformer ()</b></h5><br>\n",
    "3.1. <b>Ridge</b>(alpha=2.95, max_iter=1000, random_state=44) | gs was {'alpha': np.arange(0.00, 3.0, 0.05), 'max_iter': [1000, None], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.110<br>\n",
    "R2: 0.921 <br>\n",
    "kaggle: <b>0.13981</b>\n",
    "\n",
    "3.2. <b>Lasso</b>(alpha=0.001, max_iter=100, random_state=44) | gs was {'alpha': np.arange(0.001, 1.0, 0.002), 'max_iter': [100, 300, 1000, None], 'random_state': [rst]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.110<br>\n",
    "R2: 0.921 <br>\n",
    "kaggle: <b>0.14141 </b>\n",
    "\n",
    "3.3. <b>Stack model</b> of 3.1 and 3.2<br>\n",
    "LinearRegression<br>\n",
    "kaggle: <b>0.13672</b><br>\n",
    "\n",
    "3.4. <b>SVR</b>(C=10, coef0=10, degree=2, kernel='poly') | gs was {'C': [1, 5, 10, 24], 'degree': [1, 2, 3], 'coef0': [0, 5, 10], 'kernel': [\"poly\", \"rbf\", \"sigmoid\"]}<br>\n",
    "Testing performance<br>\n",
    "RMSE: 0.108<br>\n",
    "R2: 0.924 <br>\n",
    "kaggle 0.14329\n",
    "\n",
    "3.5. <b>Stack model</b> of 3.1, 3.2 and 3.3 <br>\n",
    "LinearRegression<br>\n",
    "kaggle: <b>0.14156</b><br>\n",
    "\n",
    "3.6. <b>Stack model</b> of 3.1, 3.2 with StandartScaler <br>\n",
    "LinearRegression<br>\n",
    "kaggle: <b>0.14045</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linear models\n",
    "\n",
    "cat_cols_oe = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "cat_cols_oh = ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', \\\n",
    "               'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \\\n",
    "                'Heating', 'CentralAir', 'Electrical', 'Functional', 'GarageType', 'GarageFinish', 'PavedDrive', 'Fence', 'SaleType', \\\n",
    "                'SaleCondition', 'MSSubClass', 'OverallCond', 'KitchenAbvGr', 'MoSold', 'YrSold']\n",
    "\n",
    "cat_cols_tdrop = ['Street', 'Utilities', 'LandSlope', 'Condition2', 'RoofMatl', 'PoolQC', 'MiscFeature', 'MiscVal']\n",
    "\n",
    "num_cols_norm = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', \\\n",
    "                 '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF'] #'GrLivArea', \n",
    "\n",
    "num_cols_asis = ['OverallQual', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\n",
    "\n",
    "num_cols_tdrop = ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'] #'1stFlrSF', '2ndFlrSF'\n",
    "\n",
    "num_cols_flag = ['BsmtFinSF2', 'LowQualFinSF', '3SsnPorch', 'PoolArea']\n",
    "\n",
    "#outliers\n",
    "rem_id = [250, 314, 336, 496, 584, 935, 1299, 1329]\n",
    "\n",
    "ifeatures = ['1stFlrSF', '2ndFlrSF', 'LotArea', 'TotalBsmtSF', 'OpenPorchSF',\n",
    "       'BsmtFinSF1', 'GarageArea', 'YearRemodAdd', 'OverallQual', 'YearBuilt',\n",
    "       'LotFrontage', 'BsmtUnfSF', 'GarageYrBlt', 'MasVnrArea', 'Bath',\n",
    "       'WoodDeckSF', 'EnclosedPorch', 'CentralAir_N', 'HeatingQC',\n",
    "       'KitchenQual', 'OverallCond_5.0', 'SaleCondition_Normal', 'FireplaceQu',\n",
    "       'GarageCars', 'OverallCond_3.0', 'OverallCond_4.0', 'BedroomAbvGr',\n",
    "       'TotRmsAbvGrd', 'SaleCondition_Abnorml', 'MSZoning_RL',\n",
    "       'Functional_Typ', 'BsmtExposure_Gd', 'Condition1_Norm', 'ScreenPorch',\n",
    "       'BsmtCond', 'OverallCond_7.0', 'BsmtQual', 'ExterCond',\n",
    "       'Neighborhood_Crawfor', 'YrSold_2009.0', 'Exterior1st_BrkFace',\n",
    "       'BsmtExposure_No', 'GarageQual', 'GarageType_Attchd',\n",
    "       'Neighborhood_Edwards', 'ExterQual', 'MoSold_12.0', 'YrSold_2006.0',\n",
    "       'Neighborhood_BrkSide', 'Neighborhood_IDOTRR', 'MSZoning_RM',\n",
    "       'Fireplaces', 'LotShape_IR1', 'Neighborhood_OldTown',\n",
    "       'Condition1_Artery', 'YrSold_2007.0', 'Electrical_FuseA', 'SaleType_WD',\n",
    "       'BsmtFinType1_ALQ', 'SaleType_New', 'Neighborhood_StoneBr',\n",
    "       'GarageType_Detchd', 'LotConfig_CulDSac', 'Neighborhood_NAmes',\n",
    "       'BsmtFinType1_Rec', 'MSSubClass_30.0', 'GarageCond', 'KitchenAbvGr_1.0',\n",
    "       'BsmtFinType1_GLQ', 'BldgType_1Fam', 'Neighborhood_Somerst',\n",
    "       'BsmtFinType2_BLQ', 'GarageFinish_Fin', 'LotConfig_FR2', 'GrLivArea'] #'GrLivArea'\n",
    "\n",
    "col_tdrop_linm = ['ExterQual', 'LotShape_IR1', 'TotRmsAbvGrd', 'MSZoning_Rm', 'GarageCond', 'GarageCars', 'SaleType_New', 'GarageType_Detchd']\n",
    "\n",
    "rst = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train / validation\n",
    "tdf = df.copy()\n",
    "tdf = fill_miss(tdf)\n",
    "\n",
    "#remove outliers\n",
    "tdf = tdf[~tdf['Id'].isin(rem_id)]\n",
    "\n",
    "# normalizing\n",
    "power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "tdf[num_cols_norm] = power.fit_transform(tdf[num_cols_norm])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# tdf[num_cols_norm] = scaler.fit_transform(tdf[num_cols_norm])\n",
    "\n",
    "tdf = feat_eng(tdf, num_cols_tdrop, num_cols_norm, num_cols_flag)\n",
    "tdf = transf_cat(tdf, cat_cols_oh, cat_cols_oe, cat_cols_tdrop)\n",
    "label = np.log1p(tdf['SalePrice'])\n",
    "tdf.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# ifeatures = list(set(ifeatures).difference(col_tdrop_linm))\n",
    "\n",
    "tdf = tdf[ifeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "test_data = fill_miss(test_data)\n",
    "# normalizing\n",
    "test_data[num_cols_norm] = power.transform(test_data[num_cols_norm])\n",
    "# test_data[num_cols_norm] = scaler.transform(test_data[num_cols_norm])\n",
    "test_data = feat_eng(test_data, num_cols_tdrop, num_cols_norm, num_cols_flag)\n",
    "test_data = transf_cat(test_data, cat_cols_oh, cat_cols_oe, cat_cols_tdrop)\n",
    "t_id = test_data['Id']\n",
    "test_data.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "test_data = test_data[ifeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tdf, label, test_size=0.25, random_state=rst)\n",
    "models_train_pred = pd.DataFrame()\n",
    "models_test_pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=2.95, max_iter=1000, random_state=44)\n",
      "Testing performance\n",
      "RMSE: 0.108\n",
      "R2: 0.925 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "\n",
    "# params_lasso = {'alpha': np.arange(0.00, 3.0, 0.05), 'max_iter': [1000, None], 'random_state': [rst]}\n",
    "params_lasso = {'alpha': [2.95], 'max_iter': [1000], 'random_state': [rst]}\n",
    "\n",
    "gs_alg = GridSearchCV(model, param_grid = params_lasso, cv = 10, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "gs_alg.fit(X_train, y_train)\n",
    "\n",
    "print(gs_alg.best_estimator_)\n",
    "\n",
    "pred = gs_alg.predict(X_test)\n",
    "pred_t = gs_alg.predict(test_data)\n",
    "models_train_pred[model.__class__.__name__] = pred\n",
    "models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.001, max_iter=300, random_state=44)\n",
      "Testing performance\n",
      "RMSE: 0.109\n",
      "R2: 0.923 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Lasso()\n",
    "\n",
    "#params_lasso = {'alpha': np.arange(0.001, 1.0, 0.002), 'max_iter': [100, 300, 1000], 'random_state': [rst]}\n",
    "params_lasso = {'alpha': [0.001], 'max_iter': [300], 'random_state': [rst]}\n",
    "\n",
    "gs_alg = GridSearchCV(model, param_grid = params_lasso, cv = 10, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "gs_alg.fit(X_train, y_train)\n",
    "\n",
    "print(gs_alg.best_estimator_)\n",
    "\n",
    "pred = gs_alg.predict(X_test)\n",
    "pred_t = gs_alg.predict(test_data)\n",
    "models_train_pred[model.__class__.__name__] = pred\n",
    "models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(models_train_pred, y_test)\n",
    "# fin_pred = model.predict(models_test_pred)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_lm_stack.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack\n",
    "\n",
    "# model = LinearRegression()\n",
    "# scaler = StandardScaler()\n",
    "# models_train_pred_st = scaler.fit_transform(models_train_pred)\n",
    "# models_test_pred_st = scaler.transform(models_test_pred)\n",
    "\n",
    "# model.fit(models_train_pred_st, y_test)\n",
    "# fin_pred = model.predict(models_test_pred_st)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_upd_pp_stack.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check feature importance\n",
    "# imp = np.abs(gs_alg.best_estimator_.coef_)\n",
    "# df_if = pd.DataFrame()\n",
    "# df_if[\"feat\"] = ifeatures\n",
    "# df_if[\"lasso_imp\"] = imp\n",
    "# df_if.sort_values(by='lasso_imp',ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non linear models\n",
    "\n",
    "nothing there yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare train / validation\n",
    "# tdf = df.copy()\n",
    "# tdf = fill_miss(tdf)\n",
    "\n",
    "# #remove outliers\n",
    "# tdf = tdf[~tdf['Id'].isin(rem_id)]\n",
    "\n",
    "# # normalizing\n",
    "# power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "# tdf[num_cols_norm] = power.fit_transform(tdf[num_cols_norm])\n",
    "\n",
    "# # scaler = MinMaxScaler()\n",
    "# # tdf[num_cols_norm] = scaler.fit_transform(tdf[num_cols_norm])\n",
    "\n",
    "# tdf = feat_eng(tdf, num_cols_tdrop, num_cols_norm, num_cols_flag)\n",
    "# tdf = transf_cat(tdf, cat_cols_oh, cat_cols_oe, cat_cols_tdrop)\n",
    "# label = np.log1p(tdf['SalePrice'])\n",
    "# tdf.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# tdf = tdf[ifeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# test_data = fill_miss(test_data)\n",
    "# # normalizing\n",
    "# test_data[num_cols_norm] = power.transform(test_data[num_cols_norm])\n",
    "# # test_data[num_cols_norm] = scaler.transform(test_data[num_cols_norm])\n",
    "# test_data = feat_eng(test_data, num_cols_tdrop, num_cols_norm, num_cols_flag)\n",
    "# test_data = transf_cat(test_data, cat_cols_oh, cat_cols_oe, cat_cols_tdrop)\n",
    "# t_id = test_data['Id']\n",
    "# test_data.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# test_data = test_data[ifeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(tdf, label, test_size=0.25, random_state=rst)\n",
    "# # models_train_pred = pd.DataFrame()\n",
    "# # models_test_pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVR()\n",
    "\n",
    "# # params_svr = {'C': [1, 5, 10, 24], \n",
    "# #             'degree': [1, 2, 3],\n",
    "# #             'coef0': [0, 5, 10],\n",
    "# #             'kernel': [\"poly\", \"rbf\", \"sigmoid\"]}\n",
    "\n",
    "# params_svr = {'C': [10], \n",
    "#             'degree': [2],\n",
    "#             'coef0': [10],\n",
    "#             'kernel': [\"poly\"]}\n",
    "\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_svr, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(X_train, y_train)\n",
    "\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# pred = gs_alg.predict(X_test)\n",
    "# pred_t = gs_alg.predict(test_data)\n",
    "# models_train_pred[model.__class__.__name__] = pred\n",
    "# models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "# rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "# r2 = r2_score(y_test, pred)\n",
    "# print('Testing performance')\n",
    "# print('RMSE: {:.3f}'.format(rmse))\n",
    "# print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor()\n",
    "\n",
    "# # params_xgb = {'n_estimators': [400, 700, 1000],\n",
    "# #         'colsample_bytree': [0.7, 0.8],\n",
    "# #         'max_depth': [15,20,25],\n",
    "# #         'reg_alpha': [1.1, 1.2, 1.3],\n",
    "# #         'reg_lambda': [1.1, 1.2, 1.3],\n",
    "# #         'subsample': [0.7, 0.8, 0.9]\n",
    "# #     }\n",
    "\n",
    "\n",
    "# params_xgb = {'n_estimators': [1000],\n",
    "#         'colsample_bytree': [1],\n",
    "#         'max_depth': [4],\n",
    "#         # 'reg_alpha': [1.1, 1.2, 1.3],\n",
    "#         # 'reg_lambda': [1.1, 1.2, 1.3],\n",
    "#         # 'subsample': [0.7, 0.8, 0.9]\n",
    "#     }\n",
    "\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_xgb, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(X_train, y_train)\n",
    "\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# pred = gs_alg.predict(X_test)\n",
    "# pred_t = gs_alg.predict(test_data)\n",
    "# models_train_pred[model.__class__.__name__] = pred\n",
    "# models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "# rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "# r2 = r2_score(y_test, pred)\n",
    "# print('Testing performance')\n",
    "# print('RMSE: {:.3f}'.format(rmse))\n",
    "# print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(learning_rate=0.03, max_depth=4, n_estimators=250, num_leaves=50,\n",
      "              verbose=-1)\n",
      "Testing performance\n",
      "RMSE: 0.117\n",
      "R2: 0.911 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor(verbose=-1)\n",
    "\n",
    "# params_lgbm = {'n_estimators': [400, 1000],\n",
    "#         'learning_rate': [0.1],\n",
    "#         # 'colsample_bytree': [0.7, 0.8],\n",
    "#         'max_depth': [4, 8, 12],\n",
    "#         'num_leaves': [10, 50, 100, 150],\n",
    "#         'reg_alpha': [1.1, 1.2],\n",
    "#         'reg_lambda': [1.1, 1.2],\n",
    "#         'min_split_gain': [0.3, 0.4],\n",
    "#         'subsample': [0.8, 0.9],\n",
    "#         'subsample_freq': [10, 20]}\n",
    "\n",
    "# params_lgbm = {'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "#                 \"max_depth\": [4, 8, 12],\n",
    "#                 \"num_leaves\": [100, 180], \n",
    "#                 # \"max_bin\": [200],\n",
    "#                 'n_estimators': [250, 400]}\n",
    "\n",
    "params_lgbm = {'learning_rate': [0.03],\n",
    "                \"max_depth\": [4],\n",
    "                \"num_leaves\": [50], \n",
    "                # \"max_bin\": [200],\n",
    "                'n_estimators': [250]}\n",
    "\n",
    "\n",
    "gs_alg = GridSearchCV(model, param_grid = params_lgbm, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "gs_alg.fit(X_train, y_train)\n",
    "\n",
    "print(gs_alg.best_estimator_)\n",
    "\n",
    "pred = gs_alg.predict(X_test)\n",
    "pred_t = gs_alg.predict(test_data)\n",
    "models_train_pred[model.__class__.__name__] = pred\n",
    "models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostRegressor object at 0x14211a170>\n",
      "Testing performance\n",
      "RMSE: 0.112\n",
      "R2: 0.919 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = cb.CatBoostRegressor(verbose=False, loss_function='RMSE')\n",
    "\n",
    "params_cb = {'iterations': [400],\n",
    "        'learning_rate': [0.1],\n",
    "        'depth': [4],\n",
    "        'l2_leaf_reg': [0.5]}\n",
    "\n",
    "\n",
    "# grid = {'learning_rate': [0.03, 0.1],\n",
    "#         'depth': [4, 6, 10],\n",
    "#         'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "# grid_search_result = model.grid_search(params_cb, X=X_train, y=y_train, verbose=False)\n",
    "\n",
    "gs_alg = GridSearchCV(model, param_grid = params_cb, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "gs_alg.fit(X_train, y_train)\n",
    "\n",
    "print(gs_alg.best_estimator_)\n",
    "\n",
    "pred = gs_alg.predict(X_test)\n",
    "pred_t = gs_alg.predict(test_data)\n",
    "models_train_pred[model.__class__.__name__] = pred\n",
    "models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=35, max_features=25, min_samples_leaf=3,\n",
      "                      min_samples_split=6, n_estimators=500)\n",
      "Testing performance\n",
      "RMSE: 0.126\n",
      "R2: 0.898 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestRegressor()\n",
    "\n",
    "# # params_rfr = {'max_depth':[13, 20, 25, 30, 50],\n",
    "# #         'n_estimators':[100, 400, 900],\n",
    "# #         'max_features':[2, 6, 10, 15, 20]}\n",
    "\n",
    "# # params_rfr = {'max_depth':[30],\n",
    "# #         'n_estimators':[400],\n",
    "# #         'max_features':[15]}\n",
    "\n",
    "# params_rfr = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [30, 35, 40], #80, 90, 100, 110],\n",
    "#     'max_features': [20, 25, 30], #10, 15, \n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [4, 6, 8], #10, 12],\n",
    "#     'n_estimators': [400, 500, 600]\n",
    "# }\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_rfr, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(X_train, y_train)\n",
    "\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# pred = gs_alg.predict(X_test)\n",
    "# pred_t = gs_alg.predict(test_data)\n",
    "# models_train_pred[model.__class__.__name__] = pred\n",
    "# models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "# rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "# r2 = r2_score(y_test, pred)\n",
    "# print('Testing performance')\n",
    "# print('RMSE: {:.3f}'.format(rmse))\n",
    "# print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(data=models_train_pred, x='Ridge', y='RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack\n",
    "\n",
    "# model = XGBRegressor()\n",
    "\n",
    "# model.fit(models_train_pred, y_test)\n",
    "# fin_pred = model.predict(models_test_pred)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_all_stack_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(learning_rate=0.03, max_bin=200, max_depth=4, n_estimators=250,\n",
      "              num_leaves=100, verbose=-1)\n"
     ]
    }
   ],
   "source": [
    "# # Stack\n",
    "# model = LGBMRegressor(verbose=-1)\n",
    "\n",
    "# # params_lgbm = {'n_estimators': [400, 1000],\n",
    "# #         'learning_rate': [0.1],\n",
    "# #         # 'colsample_bytree': [0.7, 0.8],\n",
    "# #         'max_depth': [4, 8, 12],\n",
    "# #         'num_leaves': [10, 50, 100, 150],\n",
    "# #         'reg_alpha': [1.1, 1.2],\n",
    "# #         'reg_lambda': [1.1, 1.2],\n",
    "# #         'min_split_gain': [0.3, 0.4],\n",
    "# #         'subsample': [0.8, 0.9],\n",
    "# #         'subsample_freq': [10, 20]}\n",
    "\n",
    "# # params_lgbm = {'learning_rate': [0.03, 0.05, 0.1],\n",
    "# #                 \"max_depth\": [4, 8, 12],\n",
    "# #                 \"num_leaves\": [100, 180], \n",
    "# #                 \"max_bin\": [200, 300],\n",
    "# #                 'n_estimators': [250, 400]}\n",
    "\n",
    "# params_lgbm = {'learning_rate': [0.03],\n",
    "#                 \"max_depth\": [4],\n",
    "#                 \"num_leaves\": [100], \n",
    "#                 \"max_bin\": [200],\n",
    "#                 'n_estimators': [250]}\n",
    "\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_lgbm, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(models_train_pred, y_test)\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# fin_pred = gs_alg.predict(models_test_pred)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_lm_cb_stack_lgb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack\n",
    "\n",
    "# # params_cb = {'iterations': [100, 400, 600],\n",
    "# #              'learning_rate': [0.03, 0.1],\n",
    "# #             'depth': [4, 6, 10],\n",
    "# #             'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "# # model = cb.CatBoostRegressor(verbose=False, loss_function='RMSE')\n",
    "# # grid_search_result = model.grid_search(params_cb, X=models_train_pred, y=y_test, verbose=False)\n",
    "\n",
    "# model = cb.CatBoostRegressor(verbose=False, loss_function='RMSE', depth=4, l2_leaf_reg=1, iterations=600, learning_rate=0.03)\n",
    "\n",
    "# model.fit(models_train_pred, y_test)\n",
    "# fin_pred = model.predict(models_test_pred)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_all_stack_cb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(models_train_pred, y_test)\n",
    "fin_pred = model.predict(models_test_pred)\n",
    "\n",
    "# create submission file\n",
    "subm = pd.DataFrame()\n",
    "subm['Id'] = t_id.astype('int')\n",
    "subm['SalePrice'] = np.expm1(fin_pred)\n",
    "subm.set_index('Id').to_csv('subm_lm_cb_lg_rf_stack.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>117942.636006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>161086.771046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>186073.168640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>198620.073365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>200624.923272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>85027.052034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>80720.100692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>173629.217146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>116238.333080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>237869.749412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  117942.636006\n",
       "1     1462  161086.771046\n",
       "2     1463  186073.168640\n",
       "3     1464  198620.073365\n",
       "4     1465  200624.923272\n",
       "...    ...            ...\n",
       "1454  2915   85027.052034\n",
       "1455  2916   80720.100692\n",
       "1456  2917  173629.217146\n",
       "1457  2918  116238.333080\n",
       "1458  2919  237869.749412\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lera's Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lera's addition to preprocessing\n",
    "\n",
    "# cat_onehot = [\n",
    "#     'MSZoning', 'LotConfig', 'Neighborhood', 'BldgType', 'Exterior1st', 'Exterior2nd', 'Foundation',\n",
    "#     'BsmtExposure', 'GarageType', 'Fence', 'SaleType', 'SaleCondition', 'Heating'\n",
    "# ]\n",
    "\n",
    "# cols_to_drop = [\n",
    "#     'Street', 'Alley', 'LotShape', 'LandContour', 'LandSlope', 'Condition2', 'HouseStyle', 'RoofStyle',\n",
    "#     'RoofMatl', 'MasVnrType', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageQual',\n",
    "#     'GarageCond', 'PoolQC', 'MiscFeature', 'LotFrontage', 'MasVnrArea', 'MiscVal',\n",
    "#     'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def updating_features(df):\n",
    "#     \"\"\"Creating ordinal & boolean features out of categorical/numerical\"\"\"\n",
    "    \n",
    "#     dfc = df.copy()\n",
    "    \n",
    "#     # fillna (w/respect to value distribution)\n",
    "#     dfc['BsmtExposure'].fillna('No', inplace=True)\n",
    "#     dfc['BsmtCond'] = dfc['BsmtCond'].fillna(df['BsmtCond'].mode()[0])  # before we convert to ordinal\n",
    "#     dfc['BsmtQual'] = dfc['BsmtQual'].fillna(df['BsmtQual'].mode()[0])  # before we convert to ordinal\n",
    "    \n",
    "#     # ordinal\n",
    "#     dfc['Utilities'] = dfc['Utilities'].replace({'AllPub': 100, 'NoSewr': 75,\n",
    "#                                                  'NoSeWa': 50, 'ELO': 25})\n",
    "    \n",
    "#     dfc['Condition1'] = dfc['Condition1'].replace({'Feedr': -5, 'Artery': -5,\n",
    "#                                                    'RRNn': -5, 'RRAn': -5,\n",
    "#                                                    'RRNe': -5, 'RRAe': -5,\n",
    "#                                                    'Norm': 0,\n",
    "#                                                    'PosN': 5, 'PosA': 5})\n",
    "    \n",
    "#     # boolean\n",
    "#     dfc['RegularLot'] = (dfc['LotShape'] == 'Reg').astype(int)\n",
    "#     dfc['LevelLand'] = (dfc['LandContour'] == 'Lvl').astype(int)\n",
    "#     dfc['GtlSlope'] = (dfc['LandSlope'] == 'Gtl').astype(int)\n",
    "#     dfc['HipRoof'] = (dfc['RoofStyle'] == 'Hip').astype(int)\n",
    "#     dfc['BrickOrStone'] = dfc['MasVnrType'].isin(['BrkFace', 'Stone']).astype(int)\n",
    "#     dfc['GLQ'] = (dfc['BsmtFinType1'] == 'GLQ').astype(int)\n",
    "#     dfc['CentralAir'] = (dfc['CentralAir'] == 'Y').astype(int)\n",
    "#     dfc['SBrkr'] = (dfc['Electrical'] == 'SBrkr').astype(int)\n",
    "#     dfc['Functional'] = (dfc['Functional'] == 'Typ').astype(int)\n",
    "#     dfc['HasGoodFireplace'] = dfc['FireplaceQu'].isin(['Gd', 'TA', 'Fa', 'Ex']).astype(int)\n",
    "#     dfc['GarageFinish'] = dfc['GarageFinish'].isin(['Fin', 'RFin']).astype(int)\n",
    "#     dfc['PavedDrive'] = (dfc['PavedDrive'] == 'Y').astype(int)\n",
    "    \n",
    "#     top10neighborhoods = ['Blmngtn', 'SWISU', 'Edwards', 'Somerst', 'NoRidge', 'Timber', 'CollgCr']\n",
    "#     dfc['NeighborhoodTop10'] = dfc['Neighborhood'].isin(top10neighborhoods).astype(int)\n",
    "    \n",
    "#     # uniting small categories\n",
    "#     dfc['LotConfig'] = dfc['LotConfig'].replace({'FR2': 'Other', 'FR3': 'Other'})\n",
    "#     dfc['HouseStyle'] = np.where(dfc['HouseStyle'].isin(['1.5Unf', '2.5Fin', '2.5Unf']),\n",
    "#                                  'Other',\n",
    "#                                  dfc['HouseStyle'])\n",
    "    \n",
    "#     ext_enough_observations = dfc['Exterior1st'].value_counts()[dfc['Exterior1st'].value_counts().ge(50)].keys()\n",
    "#     dfc['Exterior1st'] = np.where(dfc['Exterior1st'].isin(ext_enough_observations), \n",
    "#                                   dfc['Exterior1st'],\n",
    "#                                   'Other')\n",
    "#     ext2_enough_observations = dfc['Exterior2nd'].value_counts()[dfc['Exterior2nd'].value_counts().ge(50)].keys()\n",
    "#     dfc['Exterior2nd'] = np.where(dfc['Exterior2nd'].isin(ext2_enough_observations), \n",
    "#                                   dfc['Exterior2nd'],\n",
    "#                                   'Other')\n",
    "    \n",
    "#     dfc['Heating'] = np.where(dfc['Heating'] == 'GasA', 'Gas', 'Other')\n",
    "    \n",
    "#     # quality dict\n",
    "#     quality_dict = {'Ex': 10, 'Gd': 5, 'TA': 0, 'NA': 0, 'Fa': -5, 'Po': -10}\n",
    "#     quality_cols = [\n",
    "#         'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual'\n",
    "#     ]\n",
    "#     dfc[quality_cols] = dfc[quality_cols].replace(quality_dict)\n",
    "    \n",
    "#     # one feature instead of many\n",
    "#     dfc['TotalBaths'] = dfc[['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']].fillna(0).sum(1)\n",
    "    \n",
    "#     return dfc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OrdinalEncoder, StandardScaler, PowerTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# def fill_miss(df):\n",
    "\n",
    "#     df_upd = df.copy()\n",
    "\n",
    "#     # fill columns wheare missing values have a meaning NA\n",
    "#     feat_wn = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu',\n",
    "#        'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtFinType2', 'BsmtExposure',\n",
    "#        'BsmtFinType1', 'BsmtCond', 'BsmtQual']\n",
    "    \n",
    "#     for c in df_upd.columns:\n",
    "#         if c in feat_wn:\n",
    "#             df_upd[c].fillna('NA', inplace=True)\n",
    "\n",
    "#     # fill with mean missing num features\n",
    "#     num_si = SimpleImputer(strategy='mean')\n",
    "#     num_col= df_upd.dtypes[df_upd.dtypes != 'object']\n",
    "#     df_upd[num_col.index] = num_si.fit_transform(df_upd[num_col.index])\n",
    "\n",
    "#     # fill with most frequent categorical features\n",
    "#     cat_si = SimpleImputer(strategy='most_frequent')\n",
    "#     cat_col= df_upd.dtypes[df_upd.dtypes == 'object']\n",
    "#     df_upd[cat_col.index] = cat_si.fit_transform(df_upd[cat_col.index])\n",
    "\n",
    "\n",
    "#     return df_upd\n",
    "\n",
    "# def feat_eng(df, num_cols_tdrop, num_cols_norm, num_cols_flag):\n",
    "#     df_upd = df.copy()\n",
    "\n",
    "\n",
    "#     # create new feature for bathrooms\n",
    "#     # corr coef\n",
    "#     #     0.22512486719612368\n",
    "#     # -0.012188876310787316\n",
    "#     # 0.6359570562496957\n",
    "#     # 0.34300754918568294\n",
    "\n",
    "#     df_upd['Bath'] = 0.225 * df['BsmtFullBath'] + (-0.0121) * df['BsmtHalfBath'] + 0.636 * df['FullBath'] + 0.343 * df['HalfBath']\n",
    "\n",
    "#     # drop columns\n",
    "#     df_upd = df_upd.drop(num_cols_tdrop, axis=1)\n",
    "\n",
    "#     # # normalizing\n",
    "#     # power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "#     # df_upd[num_cols_norm] = power.fit_transform(df_upd[num_cols_norm])\n",
    "\n",
    "#     for c in num_cols_flag:\n",
    "#         if c in df_upd.columns:\n",
    "#             df_upd[c] = df_upd[c].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "\n",
    "#     return df_upd\n",
    "\n",
    "# def transf_cat(df, cat_cols_oh, cat_cols_oe, cat_cols_tdrop):\n",
    "#     df_upd = df.copy()\n",
    "\n",
    "#     # merge values in LotConfig\n",
    "#     if 'LotConfig' in  df_upd.columns:\n",
    "#         df_upd.loc[df_upd['LotConfig']=='FR3', 'LotConfig'] = 'FR2'\n",
    "\n",
    "\n",
    "#     #\n",
    "#     if 'LandSlope' in  df_upd.columns:\n",
    "#         df_upd.loc[df_upd['LandSlope']=='Sev', 'LandSlope'] = 'Mod'\n",
    "#         df_upd['GtlSlope'] = df_upd['LandSlope'].apply(lambda x: 1 if x=='Gtl' else 0)\n",
    "#         df_upd[['LandSlope', 'GtlSlope']][:5]\n",
    "\n",
    "#     # merge values in Conditional1\n",
    "#     for cc in [['RRNn', 'RRAn'], ['RRNe', 'RRAe'], ['PosN', 'PosA']]:\n",
    "#         df_upd.loc[df_upd['Condition1']==cc[0], 'Condition1'] = cc[1]\n",
    "\n",
    "\n",
    "#     # transform \n",
    "#     oec = OrdinalEncoder(categories = [['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']]) \n",
    "#     # for cc in ['FireplaceQu', 'KitchenQual', 'HeatingQC', 'PoolQC', 'BsmtQual', 'ExterQual', 'ExterCond']:\n",
    "#     for cc in cat_cols_oe:\n",
    "#         if cc in df_upd.columns:\n",
    "#             df_upd[cc] = oec.fit_transform(df_upd[[cc]])\n",
    "\n",
    "    \n",
    "#     class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "#         def __init__(self, *args, pandas_params={}, **kwargs):\n",
    "#             super().__init__(*args, **kwargs)\n",
    "#             self._pandas_params = pandas_params\n",
    "#         def fit(self, X, y=None):\n",
    "#             return self\n",
    "#         def transform(self, X, y=None):\n",
    "#             return pd.get_dummies(X, dtype = 'int', **self._pandas_params)\n",
    "    \n",
    "#     df_upd = GetDummiesTransformer(pandas_params={'columns':cat_cols_oh}).transform(df_upd)\n",
    "\n",
    "#     df_upd = df_upd.drop(cat_cols_tdrop, axis=1)\n",
    "\n",
    "#     return df_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass  LotArea  Utilities  Condition1  OverallQual  OverallCond  \\\n",
       "0  1.0        60.0   8450.0      100.0         0.0          7.0          5.0   \n",
       "1  2.0        20.0   9600.0      100.0        -5.0          6.0          8.0   \n",
       "2  3.0        60.0  11250.0      100.0         0.0          7.0          5.0   \n",
       "3  4.0        70.0   9550.0      100.0         0.0          7.0          5.0   \n",
       "4  5.0        60.0  14260.0      100.0         0.0          8.0          5.0   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  ExterQual  ...  SaleCondition_Partial  \\\n",
       "0     2003.0        2003.0        5.0  ...                      0   \n",
       "1     1976.0        1976.0        0.0  ...                      0   \n",
       "2     2001.0        2002.0        5.0  ...                      0   \n",
       "3     1915.0        1970.0        0.0  ...                      0   \n",
       "4     2000.0        2000.0        5.0  ...                      0   \n",
       "\n",
       "   SaleType_COD  SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  \\\n",
       "0             0             0             0               0               0   \n",
       "1             0             0             0               0               0   \n",
       "2             0             0             0               0               0   \n",
       "3             0             0             0               0               0   \n",
       "4             0             0             0               0               0   \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \n",
       "0               0             0             0            1  \n",
       "1               0             0             0            1  \n",
       "2               0             0             0            1  \n",
       "3               0             0             0            1  \n",
       "4               0             0             0            1  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Lera's version\n",
    "\n",
    "# tdf = df.copy()\n",
    "\n",
    "# # updating cols\n",
    "# tdf = updating_features(df)\n",
    "\n",
    "# # dropping unnecessary\n",
    "# tdf.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# # filling missing values\n",
    "# tdf = fill_miss(tdf)\n",
    "\n",
    "# # creating dummy variables\n",
    "# assert tdf.select_dtypes(include='object').columns.tolist().sort() == cat_onehot.sort()\n",
    "# onehot = pd.get_dummies(tdf[cat_onehot]).astype(int)\n",
    "# tdf = tdf.select_dtypes(exclude='object').join(onehot)\n",
    "# display(tdf.head())\n",
    "\n",
    "# # all features are numeric\n",
    "# assert tdf.select_dtypes(include='object').empty\n",
    "\n",
    "# # no missing values\n",
    "# assert tdf.isnull().sum().sum() == 0\n",
    "\n",
    "# # split to test and label\n",
    "# label = np.log1p(tdf['SalePrice'])\n",
    "# tdf.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# train_cols = tdf.columns.tolist()  # will use it later to reorder test columns\n",
    "\n",
    "# # scaling\n",
    "# power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "# tdf = power.fit_transform(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11622.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14267.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9978.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5005.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass  LotArea  Utilities  Condition1  OverallQual  \\\n",
       "0  1461.0        20.0  11622.0      100.0        -5.0          5.0   \n",
       "1  1462.0        20.0  14267.0      100.0         0.0          6.0   \n",
       "2  1463.0        60.0  13830.0      100.0         0.0          5.0   \n",
       "3  1464.0        60.0   9978.0      100.0         0.0          6.0   \n",
       "4  1465.0       120.0   5005.0      100.0         0.0          8.0   \n",
       "\n",
       "   OverallCond  YearBuilt  YearRemodAdd  ExterQual  ...  \\\n",
       "0          6.0     1961.0        1961.0        0.0  ...   \n",
       "1          6.0     1958.0        1958.0        0.0  ...   \n",
       "2          5.0     1997.0        1998.0        0.0  ...   \n",
       "3          6.0     1998.0        1998.0        0.0  ...   \n",
       "4          5.0     1992.0        1992.0        5.0  ...   \n",
       "\n",
       "   SaleCondition_Partial  SaleType_COD  SaleType_CWD  SaleType_Con  \\\n",
       "0                      0             0             0             0   \n",
       "1                      0             0             0             0   \n",
       "2                      0             0             0             0   \n",
       "3                      0             0             0             0   \n",
       "4                      0             0             0             0   \n",
       "\n",
       "   SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "0               0               0               0             0             0   \n",
       "1               0               0               0             0             0   \n",
       "2               0               0               0             0             0   \n",
       "3               0               0               0             0             0   \n",
       "4               0               0               0             0             0   \n",
       "\n",
       "   SaleType_WD  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Exterior1st_BrkFace']\n"
     ]
    }
   ],
   "source": [
    "# test_data = pd.read_csv('test.csv')\n",
    "# test = test_data.copy()\n",
    "# t_id = test_data['Id']\n",
    "\n",
    "# # updating cols\n",
    "# test = updating_features(test)\n",
    "\n",
    "# # dropping unnecessary\n",
    "# test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# # filling missing values\n",
    "# test = fill_miss(test)\n",
    "\n",
    "# # creating dummy variables\n",
    "# assert test.select_dtypes(include='object').columns.tolist().sort() == cat_onehot.sort()\n",
    "# onehot = pd.get_dummies(test[cat_onehot]).astype(int)\n",
    "# test = test.select_dtypes(exclude='object').join(onehot)\n",
    "# display(test.head())\n",
    "\n",
    "# # all features are numeric\n",
    "# assert test.select_dtypes(include='object').empty\n",
    "\n",
    "# # no missing values\n",
    "# assert test.isnull().sum().sum() == 0\n",
    "\n",
    "# # removing ids\n",
    "# test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# # adding cols missing in test (dummy cols) with 0s\n",
    "\n",
    "# missing_cols_test = [c for c in train_cols if c not in test.columns]\n",
    "# print(missing_cols_test)\n",
    "# test[missing_cols_test] = 0\n",
    "\n",
    "# # changing column order\n",
    "# test = test.loc[:, train_cols]\n",
    "\n",
    "# # scaling\n",
    "# test_data = power.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(tdf, label, test_size=0.25, random_state=rst)\n",
    "# models_train_pred = pd.DataFrame()\n",
    "# models_test_pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=2.95, max_iter=1000, random_state=44)\n",
      "Testing performance\n",
      "RMSE: 0.128\n",
      "R2: 0.900 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = Ridge()\n",
    "\n",
    "# params_ridge = {'alpha': np.arange(0.00, 3.0, 0.05), 'max_iter': [1000, None], 'random_state': [rst]}\n",
    "# # params_ridge = {'alpha': [2.95], 'max_iter': [1000], 'random_state': [rst]}\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_ridge, cv = 10, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(X_train, y_train)\n",
    "\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# pred = gs_alg.predict(X_test)\n",
    "# pred_t = gs_alg.predict(test_data)\n",
    "# models_train_pred[model.__class__.__name__] = pred\n",
    "# models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "# rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "# r2 = r2_score(y_test, pred)\n",
    "# print('Testing performance')\n",
    "# print('RMSE: {:.3f}'.format(rmse))\n",
    "# print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-02, tolerance: 1.510e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e-02, tolerance: 1.576e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e-02, tolerance: 1.533e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e-02, tolerance: 1.577e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e-02, tolerance: 1.546e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.397e-02, tolerance: 1.530e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e-02, tolerance: 1.623e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/evgenia_k/miniconda3/envs/py4dp/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e-02, tolerance: 1.565e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.005, max_iter=100, random_state=44)\n",
      "Testing performance\n",
      "RMSE: 0.123\n",
      "R2: 0.908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = Lasso()\n",
    "\n",
    "# params_lasso = {'alpha': np.arange(0.001, 1.0, 0.002), 'max_iter': [100, 300, 1000], 'random_state': [rst]}\n",
    "# # params_lasso = {'alpha': [0.001], 'max_iter': [300], 'random_state': [rst]}\n",
    "\n",
    "# gs_alg = GridSearchCV(model, param_grid = params_lasso, cv = 10, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# gs_alg.fit(X_train, y_train)\n",
    "\n",
    "# print(gs_alg.best_estimator_)\n",
    "\n",
    "# pred = gs_alg.predict(X_test)\n",
    "# pred_t = gs_alg.predict(test_data)\n",
    "# models_train_pred[model.__class__.__name__] = pred\n",
    "# models_test_pred[model.__class__.__name__] = pred_t\n",
    "\n",
    "# rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "# r2 = r2_score(y_test, pred)\n",
    "# print('Testing performance')\n",
    "# print('RMSE: {:.3f}'.format(rmse))\n",
    "# print('R2: {:.3f}'.format(r2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(models_train_pred, y_test)\n",
    "# fin_pred = model.predict(models_test_pred)\n",
    "\n",
    "# # create submission file\n",
    "# subm = pd.DataFrame()\n",
    "# subm['Id'] = t_id.astype('int')\n",
    "# subm['SalePrice'] = np.expm1(fin_pred)\n",
    "# subm.set_index('Id').to_csv('submission_lm_lera_stack.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
